{"cells":[{"cell_type":"markdown","source":["##PySpark to_date() – Convert Timestamp to Date\n\n\n---\n\n**PySpark functions provide to_date() function to convert timestamp to date (DateType), this ideally achieved by just truncating the time part from the Timestamp column. In this tutorial, I will show you a PySpark example of how to convert timestamp to date on DataFrame & SQL.**\n\n---\n\n\n**to_date() – function formats Timestamp to Date.**\n\n\n##Syntax: to_date(timestamp_column)\n##Syntax: to_date(timestamp_column,format)\n\n\n---\n\n\n**PySpark timestamp (TimestampType) consists of value in the format yyyy-MM-dd HH:mm:ss.SSSS and Date (DateType) format would be yyyy-MM-dd. Use to_date() function to truncate time from Timestamp or to convert the timestamp to date on DataFrame column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b090a3c3-b1dc-4e16-8f37-74d6f65900d2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df = spark.createDataFrame(\n        data=[ (\"1\",\"2023-01-18 12:01:19.000\")],\n        schema=[\"id\",\"input_timestamp\"])\n\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9ffef684-1d37-4e56-aa7a-804cd200f5a3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+\n|id |input_timestamp        |\n+---+-----------------------+\n|1  |2023-01-18 12:01:19.000|\n+---+-----------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+\n|id |input_timestamp        |\n+---+-----------------------+\n|1  |2023-01-18 12:01:19.000|\n+---+-----------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Using to_date() – Convert Timestamp String to Date\n\n\n**In this example, we will use to_date() function to convert TimestampType (or string) column to DateType column. The input to this function should be timestamp column or string in TimestampType format and it returns just date in DateType column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"72704a82-93f1-4a50-a5b4-e9c88dc06048","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5a195a0-b509-4b0b-9872-5a5ff2cb109c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Timestamp String to DateType\ndf.withColumn(\"date_type\", to_date(\"input_timestamp\"))\\\n.show(truncate=False)\n\n#Timestamp Type to DateType\ndf.withColumn(\"date_type\", to_date(current_timestamp()))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a3b7613f-aa84-41bc-b58d-602ca702b521","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Custom Timestamp format to DateType\ndf.select(to_date(lit('01-18-2023 12:01:19.000'), 'MM-dd-yyyy HH:mm:ss.SSS'))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eca04ed4-9470-484f-a1f8-dcd49e30f530","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------------------------------------------------+\n|to_date(01-18-2023 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSS)|\n+---------------------------------------------------------+\n|2023-01-18                                               |\n+---------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------------------------------------------------+\n|to_date(01-18-2023 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSS)|\n+---------------------------------------------------------+\n|2023-01-18                                               |\n+---------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Convert TimestampType (timestamp) to DateType (date)\n\n**This example converts the PySpark TimestampType column to DateType.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d7fb16a6-4387-4bf3-ae1f-3d99e7071036","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Timestamp Type to DateType\n\ndf.withColumn('ts', to_timestamp(col(\"input_timestamp\")))\\\n.withColumn(\"datetype\", to_date(col(\"ts\")))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"78954d38-f2cc-491d-b1e5-0ef295bdef2c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------------------+-------------------+----------+\n|id |input_timestamp        |ts                 |datetype  |\n+---+-----------------------+-------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18 12:01:19|2023-01-18|\n+---+-----------------------+-------------------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------------------+-------------------+----------+\n|id |input_timestamp        |ts                 |datetype  |\n+---+-----------------------+-------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18 12:01:19|2023-01-18|\n+---+-----------------------+-------------------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Using Column cast() Function\n\n\n**Here is another way to convert TimestampType (timestamp string) to DateType using cast function.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5ec6ef3f-2108-49e7-83f3-03fa57ef156a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Using Cast to convert Timestamp String to DateType\n\ndf.withColumn('date_type', col('input_timestamp').cast('date'))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"973891eb-9dfd-40d3-932c-5737517265ef","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------------------+----------+\n|id |input_timestamp        |date_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Using Cast to convert Timestamp to DataType\n\ndf.withColumn('data_type', to_timestamp('input_timestamp').cast('date'))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"595ddf14-4d92-4615-8ecc-6e14e91bdc40","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------------------+----------+\n|id |input_timestamp        |data_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------------------+----------+\n|id |input_timestamp        |data_type |\n+---+-----------------------+----------+\n|1  |2023-01-18 12:01:19.000|2023-01-18|\n+---+-----------------------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##PySpark SQL – Convert Timestamp to Date\n\n**Following are similar examples using with PySpark SQL. If you are from an SQL background these come in handy.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"00444077-0b81-4096-9efd-9b307dfd0b6a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# SQL TimestampType to DateType\nspark.sql(\" select to_date(CURRENT_TIMESTAMP) as date_type\").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a5bd917-5b3f-47f8-b306-634aef7fc60c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+\n|date_type |\n+----------+\n|2023-01-18|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|date_type |\n+----------+\n|2023-01-18|\n+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#SQL CAST TimestampType to DateType\nspark.sql(\" select date(to_timestamp('2019-06-24 12:01:19.000')) as date_type \").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48b215a1-9470-4a2c-b0d4-4806e0e9ca54","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# SQL CAST timestamp string to DateType\n\nspark.sql(\" SELECT date('2019-06-24 12:01:19.000') as date_type \").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6548e77a-d16d-4cef-8001-6515df20dd91","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# SQL Timestamp String (default format) to DateType\nspark.sql(\" SELECT to_date('2019-06-24 12:01:19.000') as date_type \").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bf52a678-086f-4e79-9348-a7bd5f720f04","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#SQL Custom Timeformat to DateType\n\nspark.sql(\"SELECT to_date('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as date_type \").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"268cee6c-9e07-48dd-8383-49f2ab524373","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n|date_type |\n+----------+\n|2019-06-24|\n+----------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark – to_date()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3787274238427509}},"nbformat":4,"nbformat_minor":0}
