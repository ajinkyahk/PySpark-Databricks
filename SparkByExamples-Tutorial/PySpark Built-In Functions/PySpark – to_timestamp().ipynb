{"cells":[{"cell_type":"markdown","source":["#PySpark to_timestamp() – Convert String to Timestamp type\n\n---\n\nUse <em>to_timestamp</em>() function to convert String to Timestamp (TimestampType) in PySpark. The converted time would be in a default format of MM-dd-yyyy HH:mm:ss.SSS, I will explain how to use this function with a few examples.\n\n\n---\n\n**Syntax – to_timestamp()**\n\n###Syntax: to_timestamp(timestampString:Column) \n###Syntax: to_timestamp(timestampString:Column,format:String) \n \n \n ---\n \n \n**This function has above two signatures that defined in PySpark SQL Date & Timestamp Functions, the first syntax takes just one argument and the argument should be in Timestamp format ‘MM-dd-yyyy HH:mm:ss.SSS‘, when the format is not in this format, it returns null.**\n\n\n---\n\n**The second signature takes an additional String argument to specify the format of the input Timestamp; this support formats specified in SimeDateFormat. Using this additional argument, you can cast String from any format to Timestamp type in PySpark.**\n\n\n---\n\n\n##Convert String to PySpark Timestamp type\n\n\n**In the below example we convert the string pattern which is in PySpark default format to Timestamp type, since the input DataFrame column is in default Timestamp format, we use the first signature for conversion. And the second example uses the cast function to do the same.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2026c67e-ccde-4590-ac95-845943409130","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d23a16be-4369-461d-a850-e438f261553e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame(data=[(\"1\",\"2019-06-24 12:01:19.000\")],\n                          schema=[\"id\", \"input_timestamp\"])\n\ndf.printSchema()\n\n\n#Timestamp String to DateType\n\ndf = df.withColumn(\"timestamp\", to_timestamp(\"input_timestamp\"))\ndf.show(truncate=False)\n\n\n#Using cast to convert TimestampType to DateType\n\ndf = df.withColumn(\"timestamp_string\",\\\n             to_timestamp('timestamp').cast('string'))\ndf.show(truncate=False)\n\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e0551f50-c4b4-4096-9d63-8389df04cb94","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+-------------------+\n|id |input_timestamp        |timestamp          |\n+---+-----------------------+-------------------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n+---+-----------------------+-------------------+\n\n+---+-----------------------+-------------------+-------------------+\n|id |input_timestamp        |timestamp          |timestamp_string   |\n+---+-----------------------+-------------------+-------------------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|2019-06-24 12:01:19|\n+---+-----------------------+-------------------+-------------------+\n\nroot\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestamp_string: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n\n+---+-----------------------+-------------------+\n|id |input_timestamp        |timestamp          |\n+---+-----------------------+-------------------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|\n+---+-----------------------+-------------------+\n\n+---+-----------------------+-------------------+-------------------+\n|id |input_timestamp        |timestamp          |timestamp_string   |\n+---+-----------------------+-------------------+-------------------+\n|1  |2019-06-24 12:01:19.000|2019-06-24 12:01:19|2019-06-24 12:01:19|\n+---+-----------------------+-------------------+-------------------+\n\nroot\n |-- id: string (nullable = true)\n |-- input_timestamp: string (nullable = true)\n |-- timestamp: timestamp (nullable = true)\n |-- timestamp_string: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**In this snippet, we just add a new column timestamp by converting the input column from string to Timestamp type.**\n\n\n---\n\n\n##Custom string format to Timestamp type\n\n\n**This example converts input timestamp string from custom format to PySpark Timestamp type, to do this, we use the second syntax where it takes an additional argument to specify user-defined patterns for date-time formatting,**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ba75d954-2cb4-47a2-bf2d-5f40ad9d704d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#when dates are not in Spark TimestampType format 'yyyy-MM-dd  HH:mm:ss.SSS'.\n#Note that when dates are not in Spark Tiemstamp format, all Spark functions returns null\n#Hence, first convert the input dates to Spark DateType using to_timestamp function\ndf.select(to_timestamp(lit('06-24-2019 12:01:19.000'),'MM-dd-yyyy HH:mm:ss.SSSS')) \\\n  .show(truncate=False)\n\n#Displays"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bd3f96bd-2be0-4b3f-9b47-09c19b98fe2b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------------------------------------------------------+\n|to_timestamp(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n+---------------------------------------------------------------+\n|2019-06-24 12:01:19                                            |\n+---------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------------------------------------------------------+\n|to_timestamp(06-24-2019 12:01:19.000, MM-dd-yyyy HH:mm:ss.SSSS)|\n+---------------------------------------------------------------+\n|2019-06-24 12:01:19                                            |\n+---------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**In case if you want to convert string to date format use to_date() function.**\n\n\n---\n\n\n##SQL Example"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c618ec2d-842a-407b-b4ed-cb5d393ee324","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#SQL string to TimestampType\ndf2 = spark.sql(\" select to_timestamp('2019-06-24 12:01:19.000') as timestamp \")\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa2af7ce-a872-4310-b2c1-d7246101b9ef","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- timestamp: timestamp (nullable = true)\n\n+-------------------+\n|timestamp          |\n+-------------------+\n|2019-06-24 12:01:19|\n+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- timestamp: timestamp (nullable = true)\n\n+-------------------+\n|timestamp          |\n+-------------------+\n|2019-06-24 12:01:19|\n+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#SQL CAST timestamp string to TimestampType\ndf3 = spark.sql(\" select timestamp('2019-06-24 12:01:19.000') as timestamp \")\ndf3.printSchema()\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2b071839-12c5-4e9f-aad5-290e24e4a2af","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- timestamp: timestamp (nullable = true)\n\n+-------------------+\n|timestamp          |\n+-------------------+\n|2019-06-24 12:01:19|\n+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- timestamp: timestamp (nullable = true)\n\n+-------------------+\n|timestamp          |\n+-------------------+\n|2019-06-24 12:01:19|\n+-------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#SQL Custom string to TimestampType\ndf4 = spark.sql(\" select to_timestamp('06-24-2019 12:01:19.000','MM-dd-yyyy HH:mm:ss.SSSS') as timestamp \")\ndf4.printSchema()\ndf4.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9057423e-0c0a-45be-a64b-3f8e6e61c058","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- timestamp: timestamp (nullable = true)\n\n+-------------------+\n|timestamp          |\n+-------------------+\n|2019-06-24 12:01:19|\n+-------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- timestamp: timestamp (nullable = true)\n\n+-------------------+\n|timestamp          |\n+-------------------+\n|2019-06-24 12:01:19|\n+-------------------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark – to_timestamp()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1741527542552693}},"nbformat":4,"nbformat_minor":0}
