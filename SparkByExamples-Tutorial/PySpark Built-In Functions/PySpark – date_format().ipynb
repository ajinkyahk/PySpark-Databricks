{"cells":[{"cell_type":"markdown","source":["#PySpark date_format() – Convert Date to String format\n\n\n---\n\n**In PySpark use date_format() function to convert the DataFrame column from Date to String format. In this tutorial, we will show you a Spark SQL example of how to convert Date to String format using  date_format() function on DataFrame.**\n\n\n---\n\n**date_format() – function formats Date to String format. This function supports all Java Date formats specified in DateTimeFormatter.**\n\n\n\n**Following are Syntax and Example of date_format() Function:**\n\n\n##Syntax:  date_format(column,format)\n##Example: date_format(current_timestamp(),\"yyyy MM dd\").alias(\"date_format\")\n\n\n---\n\n**The below code snippet takes the current system date from current_date() and timestamp from the current_timestamp() function and converts it to String format on DataFrame.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c707ca97-dace-403f-8ab0-d13ef67d7baa","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"22f6368a-9a9c-4d37-a789-2d942191dd27","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df = spark.createDataFrame([[\"1\"]], [\"id\"])\n\ndf.select(current_date().alias(\"current_date\"),\\\n         date_format(current_timestamp(), \"yyyy MM dd\").alias(\"yyyy MM dd\"),\\\n         date_format(current_timestamp(), \"MM/dd/yyyy hh:mm\").alias(\"MM/dd/yyyy\"),\\\n         date_format(current_timestamp(), \"yyyy MMM dd\").alias(\"yyyy MMM dd\"),\\\n         date_format(current_timestamp(), \"yyyy MMMM dd E\").alias(\"yyyy MMMM dd E\"),\\\n         date_format(lit(\"2023-09-05 14:19:02.142\"), \"yyyy MMM dd\").alias(\"yyyy MMMM dd\")).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c15c9d03-c4e4-46a5-8f10-aca3f7a46a50","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+------------+----------+----------------+-----------+--------------------+------------+\n|current_date|yyyy MM dd|MM/dd/yyyy      |yyyy MMM dd|yyyy MMMM dd E      |yyyy MMMM dd|\n+------------+----------+----------------+-----------+--------------------+------------+\n|2023-02-05  |2023 02 05|02/05/2023 02:24|2023 Feb 05|2023 February 05 Sun|2023 Sep 05 |\n+------------+----------+----------------+-----------+--------------------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------+----------+----------------+-----------+--------------------+------------+\n|current_date|yyyy MM dd|MM/dd/yyyy      |yyyy MMM dd|yyyy MMMM dd E      |yyyy MMMM dd|\n+------------+----------+----------------+-----------+--------------------+------------+\n|2023-02-05  |2023 02 05|02/05/2023 02:24|2023 Feb 05|2023 February 05 Sun|2023 Sep 05 |\n+------------+----------+----------------+-----------+--------------------+------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Alternatively, you can convert Data to String with SQL by using same functions."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b781873c-487c-4e40-b6cd-672764ca9b21","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["spark.sql(\"select current_date() as current_date, \"+\n         \"date_format(current_timestamp(), 'yyyy MM dd') as yyyy_MM_dd, \"+\n         \"date_format(current_timestamp(), 'MM/dd/yyyy hh:mm') as MM_dd_yyyy, \"+ \n         \"date_format(current_timestamp(), 'yyyy MMM dd') as yyyy_MMM_dd, \"+\n         \"date_format(current_timestamp(), 'yyyy MMMM dd E') as yyyy_MM_dd_E\").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"598e87e3-2794-47dd-9e7d-9552c7331a02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+------------+----------+----------------+-----------+--------------------+\n|current_date|yyyy_MM_dd|MM_dd_yyyy      |yyyy_MMM_dd|yyyy_MM_dd_E        |\n+------------+----------+----------------+-----------+--------------------+\n|2023-02-05  |2023 02 05|02/05/2023 02:47|2023 Feb 05|2023 February 05 Sun|\n+------------+----------+----------------+-----------+--------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------+----------+----------------+-----------+--------------------+\n|current_date|yyyy_MM_dd|MM_dd_yyyy      |yyyy_MMM_dd|yyyy_MM_dd_E        |\n+------------+----------+----------------+-----------+--------------------+\n|2023-02-05  |2023 02 05|02/05/2023 02:47|2023 Feb 05|2023 February 05 Sun|\n+------------+----------+----------------+-----------+--------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"timestamp\",current_timestamp()).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8cc986c3-9b5a-4fdd-9edb-bdda1043532f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+---+-----------------------+\n|id |timestamp              |\n+---+-----------------------+\n|1  |2023-02-05 14:19:02.142|\n+---+-----------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------------------+\n|id |timestamp              |\n+---+-----------------------+\n|1  |2023-02-05 14:19:02.142|\n+---+-----------------------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark – date_format()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2320678032373109}},"nbformat":4,"nbformat_minor":0}
