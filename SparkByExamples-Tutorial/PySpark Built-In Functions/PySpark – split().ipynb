{"cells":[{"cell_type":"markdown","source":["#PySpark Convert String to Array Column\n\n---\n\n**PySpark SQL provides split() function to convert delimiter separated String to an Array (StringType to ArrayType) column on DataFrame. This can be done by splitting a string column based on a delimiter like space, comma, pipe e.t.c, and converting it into ArrayType.**\n\n\n\n---\n\n\n**In this article, I will explain converting String to Array column using split() function on DataFrame and SQL query.**\n\n##Split() function syntax\n\n**PySpark SQL split() is grouped under Array Functions in PySpark SQL Functions class with the below syntax.**\n\n\n###pyspark.sql.functions.split(str, pattern, limit=-1)\n\n---\n\n\n**The split() function takes the first argument as the DataFrame column of type String and the second argument string delimiter that you want to split on. You can also use the pattern as a delimiter. This function returns pyspark.sql.Column of type Array.**\n\n---\n\n\n**Before we start with usage, first, let’s create a DataFrame with a string column with text separated with comma delimiter**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b8848c3b-a7b9-4291-8020-a362025fb964","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = [(\"James, A, Smith\",\"2018\",\"M\",3000),\n            (\"Michael, Rose, Jones\",\"2010\",\"M\",4000),\n            (\"Robert,K,Williams\",\"2010\",\"M\",4000),\n            (\"Maria,Anne,Jones\",\"2005\",\"F\",4000),\n            (\"Jen,Mary,Brown\",\"2010\",\"\",-1)\n            ]\n\ncolumns = [\"name\", \"dob_year\", \"gender\", \"salary\"]\ndf = spark.createDataFrame(data=data, schema=columns)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e48a65a6-d6a6-4734-8f5d-21fbbe21ec45","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- dob_year: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+--------------------+--------+------+------+\n|name                |dob_year|gender|salary|\n+--------------------+--------+------+------+\n|James, A, Smith     |2018    |M     |3000  |\n|Michael, Rose, Jones|2010    |M     |4000  |\n|Robert,K,Williams   |2010    |M     |4000  |\n|Maria,Anne,Jones    |2005    |F     |4000  |\n|Jen,Mary,Brown      |2010    |      |-1    |\n+--------------------+--------+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- dob_year: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+--------------------+--------+------+------+\n|name                |dob_year|gender|salary|\n+--------------------+--------+------+------+\n|James, A, Smith     |2018    |M     |3000  |\n|Michael, Rose, Jones|2010    |M     |4000  |\n|Robert,K,Williams   |2010    |M     |4000  |\n|Maria,Anne,Jones    |2005    |F     |4000  |\n|Jen,Mary,Brown      |2010    |      |-1    |\n+--------------------+--------+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**This yields the below output. As you notice we have a name column with takens firstname, middle and lastname with comma separated.**\n\n\n---\n\n##PySpark Convert String to Array Column\n\n\n**Below PySpark example snippet splits the String column name on comma delimiter and convert it to an Array. If you do not need the original column, use drop() to remove the column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"010b7b6b-1051-48d1-b516-6ad43bd9d33c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import col, split"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b84259d6-6370-421d-b5eb-5cb77a371475","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df2 = df.select(split(col(\"name\"), \",\").alias(\"NameArray\"))\\\n.drop(\"name\")\n\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8b384826-f6a6-4f72-bc36-133d221dae8b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- NameArray: array (nullable = true)\n |    |-- element: string (containsNull = false)\n\n+------------------------+\n|NameArray               |\n+------------------------+\n|[James,  A,  Smith]     |\n|[Michael,  Rose,  Jones]|\n|[Robert, K, Williams]   |\n|[Maria, Anne, Jones]    |\n|[Jen, Mary, Brown]      |\n+------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- NameArray: array (nullable = true)\n |    |-- element: string (containsNull = false)\n\n+------------------------+\n|NameArray               |\n+------------------------+\n|[James,  A,  Smith]     |\n|[Michael,  Rose,  Jones]|\n|[Robert, K, Williams]   |\n|[Maria, Anne, Jones]    |\n|[Jen, Mary, Brown]      |\n+------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Convert String to Array Column using SQL Query\n\n\n**Since PySpark provides a way to execute the raw SQL, let’s learn how to write the same example using Spark SQL expression.**\n\n**In order to use raw SQL, first, you need to create a table using createOrReplaceTempView(). This creates a temporary view from the Dataframe and this view is available lifetime of the current Spark context.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"deb7a2ed-dde1-418b-a747-7686bfa6540a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.createOrReplaceTempView(\"PERSON\")\nspark.sql(\" select SPLIT(name, ',') as NamedArray  from PERSON\")\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55d68582-073c-4041-ba14-d42868292534","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------------------------+\n|NamedArray              |\n+------------------------+\n|[James,  A,  Smith]     |\n|[Michael,  Rose,  Jones]|\n|[Robert, K, Williams]   |\n|[Maria, Anne, Jones]    |\n|[Jen, Mary, Brown]      |\n+------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------------------+\n|NamedArray              |\n+------------------------+\n|[James,  A,  Smith]     |\n|[Michael,  Rose,  Jones]|\n|[Robert, K, Williams]   |\n|[Maria, Anne, Jones]    |\n|[Jen, Mary, Brown]      |\n+------------------------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark – split()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1848772988164687}},"nbformat":4,"nbformat_minor":0}
