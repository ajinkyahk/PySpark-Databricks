{"cells":[{"cell_type":"markdown","source":["#PySpark When Otherwise | SQL Case When Usage\n\n---\n\n**PySpark When Otherwise and SQL Case When on DataFrame with Examples – Similar to SQL and programming languages, PySpark supports a way to check multiple conditions in sequence and returns a value when the first condition met by using SQL like case when and when().otherwise() expressions, these works similar to “Switch\" and \"if then else\" statements.**\n\n\n---\n\n\n- Using “When Otherwise” on DataFrame.\n- PySpark SQL “Case When” on DataFrame.\n- Using Multiple Conditions With & (And) | (OR) operators\n\n\n\n---\n\n\n**PySpark When Otherwise – when() is a SQL function that returns a Column type and otherwise() is a function of Column, if otherwise() is not used, it returns a None/NULL value.**\n\n\n**PySpark SQL Case When – This is similar to SQL expression, Usage: CASE WHEN cond1 THEN result WHEN cond2 THEN result... ELSE result END.**\n\n---\n\n**First, let’s create a DataFrame**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"32de65f7-3ee4-4703-a740-8feaf4ce2a91","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data =  [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n        (\"Jen\",\"\",None)]\n\ncolumns = [\"name\", \"gender\", \"salary\"]\n\ndf = spark.createDataFrame(data=data, schema=columns)\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3ba69939-d57a-423c-8509-401756192a06","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------+------+\n|name   |gender|salary|\n+-------+------+------+\n|James  |M     |60000 |\n|Michael|M     |70000 |\n|Robert |null  |400000|\n|Maria  |F     |500000|\n|Jen    |      |null  |\n+-------+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------+------+\n|name   |gender|salary|\n+-------+------+------+\n|James  |M     |60000 |\n|Michael|M     |70000 |\n|Robert |null  |400000|\n|Maria  |F     |500000|\n|Jen    |      |null  |\n+-------+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##1. Using when() otherwise() on PySpark DataFrame.\n\n\n**PySpark when() is SQL function, in order to use this first you should import and this returns a Column type, otherwise() is a function of Column, when otherwise() not used and none of the conditions met it assigns None (Null) value. Usage would be like when(condition).otherwise(default).**\n\n**when() function take 2 parameters, first param takes a condition and second takes a literal value or Column, if condition evaluates to true then it returns a value from second param.**\n\n**The below code snippet replaces the value of gender with a new derived value, when conditions not matched, we are assigning “Unknown” as value, for null assigning empty.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4bdc303-9699-4303-8302-4871fb57ec52","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import when\n\ndf2 = df.withColumn(\"new_gender\", when(df.gender == \"M\", \"Male\")\n                   .when(df.gender == \"F\", \"Female\")\n                   .when(df.gender.isNull(), \"\")\n                   .otherwise(df.gender))\n\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3eaf9345-982a-4fbf-9ba0-f11b7962160f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#Using with select()\nfrom pyspark.sql.functions import col\n\ndf2 = df.select(col(\"*\"), when(df.gender== \"M\", \"Male\")\n               .when(df.gender == \"F\", \"Female\")\n               .when(df.gender.isNull(), \"\")\n               .otherwise(df.gender).alias(\"new_gender\"))\n\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3ebcfe7c-d88d-4f78-8915-e43a578e9bba","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#2. PySpark SQL Case When on DataFrame.\n\n**If you have a SQL background you might have familiar with Case When statement that is used to execute a sequence of conditions and returns a value when the first condition met, similar to SWITCH and IF THEN ELSE statements. Similarly, PySpark SQL Case When statement can be used on DataFrame, below are some of the examples of using with withColumn(), select(), selectExpr() utilizing expr() function.**\n\n---\n\n**Syntax of SQL CASE WHEN ELSE END**\n\n\nCASE\n\n    WHEN condition1 THEN result_value1\n\n    WHEN condition2 THEN result_value2\n    -----\n    -----\n    \n    ELSE result\n\nEND;\n\n---\n\n\n- CASE is the start of the expression\n- Clause WHEN takes a condition, if condition true it returns a value from THEN\n- If the condition is false it goes to the next condition and so on.\n- If none of the condition matches, it returns a value from the ELSE clause.\n- END is to end the expression\n\n\n---\n\n\n###2.1 Using Case When Else on DataFrame using withColumn() & select()\n\n**Below example uses PySpark SQL expr() Function to express SQL like expressions.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff781645-5989-4499-9e3a-56eed19c2e54","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import col, expr\n\n#Using Case When on withColumn()\n\ndf3 = df.withColumn(\"new_gender\", expr(\" CASE WHEN gender = 'M' THEN 'Male' \"+\n                                      \" WHEN gender = 'F' THEN 'female' WHEN gender IS NULL THEN '' \" +\n                                      \"ELSE gender END\"))\n\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0bfaf3c9-007d-4857-8dd9-9d0ba6b8bacb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Using case When on select()\ndf4 = df.select(col(\"*\"), expr(\" CASE WHEN gender = 'M' THEN 'Male'\" +\n                               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\"+\n                               \"ELSE gender END\").alias(\"new_gender\"))\n\ndf4.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2228a25-ce27-46cf-b41f-beac80b62977","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+------+------+----------+\n|name   |gender|salary|new_gender|\n+-------+------+------+----------+\n|James  |M     |60000 |Male      |\n|Michael|M     |70000 |Male      |\n|Robert |null  |400000|          |\n|Maria  |F     |500000|Female    |\n|Jen    |      |null  |          |\n+-------+------+------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.1 Using Case When Else on DataFrame using withColumn() & select()\n\n\n**Below example uses PySpark SQL expr() Function to express SQL like expressions.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6045fa8e-e795-40c7-b4f5-8577abdb04aa","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.createOrReplaceTempView(\"EMP\")\n\nspark.sql(\" SELECT name, CASE WHEN gender = 'M' THEN 'Male' \"+\n         \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\"+\n         \"ELSE gender END AS new_gender FROM EMP\").show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21ba0fd8-0d70-4159-b1ec-1ec33073aae0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------+----------+\n|name   |new_gender|\n+-------+----------+\n|James  |Male      |\n|Michael|Male      |\n|Robert |          |\n|Maria  |Female    |\n|Jen    |          |\n+-------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------+----------+\n|name   |new_gender|\n+-------+----------+\n|James  |Male      |\n|Michael|Male      |\n|Robert |          |\n|Maria  |Female    |\n|Jen    |          |\n+-------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.3. Multiple Conditions using & and | operator\n\n\n**We often need to check with multiple conditions, below is an example of using PySpark When Otherwise with multiple conditions by using and (&) or (|) operators. To explain this I will use a new set of data to make it simple.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"115e29cb-c822-45ab-a677-5c07e5e8c927","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = [(66,'a',4),(67,'a',0),(70,'b',4), (71,'d',4)]\ncolumns = ['id', 'code', 'amt']\ndf5 = spark.createDataFrame(data=data, schema=columns)\n\ndf5.withColumn('new_column', when((col('code') == 'a') | (col('code') == 'd'), 'A')\n.when((col('code') == 'b') & (col('amt') == '4'), 'B')\n.otherwise('A1')).show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6ce6ec41-f7c3-472e-a9c1-4a0d7431dfae","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+----+---+----------+\n| id|code|amt|new_column|\n+---+----+---+----------+\n| 66|   a|  4|         A|\n| 67|   a|  0|         A|\n| 70|   b|  4|         B|\n| 71|   d|  4|         A|\n+---+----+---+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----+---+----------+\n| id|code|amt|new_column|\n+---+----+---+----------+\n| 66|   a|  4|         A|\n| 67|   a|  0|         A|\n| 70|   b|  4|         B|\n| 71|   d|  4|         A|\n+---+----+---+----------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark – when()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2306967802340169}},"nbformat":4,"nbformat_minor":0}
