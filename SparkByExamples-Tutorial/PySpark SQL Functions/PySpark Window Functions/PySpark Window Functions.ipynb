{"cells":[{"cell_type":"markdown","source":["##PySpark Window Functions\n\n---\n\n**PySpark Window functions are used to calculate results such as the rank, row number e.t.c over a range of input rows. In this article, I’ve explained the concept of window functions, syntax, and finally how to use them with PySpark SQL and PySpark DataFrame API. These come in handy when we need to make aggregate operations in a specific window frame on DataFrame columns.**\n\n**When possible try to leverage standard library as they are little bit more compile-time safety, handles null and perform better when compared to UDF’s. If your application is critical on performance try to avoid using custom UDF at all costs as these are not guarantee on performance.**\n\n\n---\n\n\n##1. Window Functions\n\n\n**PySpark Window functions operate on a group of rows (like frame, partition) and return a single value for every input row. PySpark SQL supports three kinds of window functions:**\n\n- ranking functions\n\n- analytic functions\n\n- aggregate functions\n\n\n---\n\n\n**To perform an operation on a group first, we need to partition the data using Window.partitionBy() , and for row number and rank function we need to additionally order by on partition data using orderBy clause.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f02701ed-1b7b-46af-b813-942903e75615","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["simpleData = (\n    (\"James\", \"Sales\", 3000), \\\n    (\"Michael\", \"Sales\", 4600),  \\\n    (\"Robert\", \"Sales\", 4100),   \\\n    (\"Maria\", \"Finance\", 3000),  \\\n    (\"James\", \"Sales\", 3000),    \\\n    (\"Scott\", \"Finance\", 3300),  \\\n    (\"Jen\", \"Finance\", 3900),    \\\n    (\"Jeff\", \"Marketing\", 3000), \\\n    (\"Kumar\", \"Marketing\", 2000),\\\n    (\"Saif\", \"Sales\", 4100) \\\n)\ncolumns = [\"employee_name\", \"department\", \"salary\"]\n\ndf = spark.createDataFrame(data=simpleData, schema=columns)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4b0fa3a-1620-4446-affd-c3206af323b4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|James        |Sales     |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- employee_name: string (nullable = true)\n |-- department: string (nullable = true)\n |-- salary: long (nullable = true)\n\n+-------------+----------+------+\n|employee_name|department|salary|\n+-------------+----------+------+\n|James        |Sales     |3000  |\n|Michael      |Sales     |4600  |\n|Robert       |Sales     |4100  |\n|Maria        |Finance   |3000  |\n|James        |Sales     |3000  |\n|Scott        |Finance   |3300  |\n|Jen          |Finance   |3900  |\n|Jeff         |Marketing |3000  |\n|Kumar        |Marketing |2000  |\n|Saif         |Sales     |4100  |\n+-------------+----------+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##2. PySpark Window Ranking functions\n\n\n###2.1 row_number Window Function\n\n\n**row_number() window function is used to give the sequential row number starting from 1 to the result of each window partition.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"abec06ed-3541-47ff-a7c6-8d7b8c22a9bc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.window import Window\nfrom pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1476127d-5680-4f1a-a79c-180eb0de8a5b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["windowSpec = Window.partitionBy(\"department\").orderBy(\"salary\")\n\n\ndf. withColumn(\"row_number\", row_number().over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f711381d-50ab-4db5-a99c-52118e9afae1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+----------+\n|employee_name|department|salary|row_number|\n+-------------+----------+------+----------+\n|Maria        |Finance   |3000  |1         |\n|Scott        |Finance   |3300  |2         |\n|Jen          |Finance   |3900  |3         |\n|Kumar        |Marketing |2000  |1         |\n|Jeff         |Marketing |3000  |2         |\n|James        |Sales     |3000  |1         |\n|James        |Sales     |3000  |2         |\n|Robert       |Sales     |4100  |3         |\n|Saif         |Sales     |4100  |4         |\n|Michael      |Sales     |4600  |5         |\n+-------------+----------+------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+----------+\n|employee_name|department|salary|row_number|\n+-------------+----------+------+----------+\n|Maria        |Finance   |3000  |1         |\n|Scott        |Finance   |3300  |2         |\n|Jen          |Finance   |3900  |3         |\n|Kumar        |Marketing |2000  |1         |\n|Jeff         |Marketing |3000  |2         |\n|James        |Sales     |3000  |1         |\n|James        |Sales     |3000  |2         |\n|Robert       |Sales     |4100  |3         |\n|Saif         |Sales     |4100  |4         |\n|Michael      |Sales     |4600  |5         |\n+-------------+----------+------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.2 rank Window Function\n\n\n**rank() window function is used to provide a rank to the result within a window partition. This function leaves gaps in rank when there are ties.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6ad3dab-1a53-4ead-b747-886e9651226b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.withColumn(\"rank\", rank().over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7787acb9-1b1d-4737-8c7a-5a0d64bccc12","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+----+\n|employee_name|department|salary|rank|\n+-------------+----------+------+----+\n|Maria        |Finance   |3000  |1   |\n|Scott        |Finance   |3300  |2   |\n|Jen          |Finance   |3900  |3   |\n|Kumar        |Marketing |2000  |1   |\n|Jeff         |Marketing |3000  |2   |\n|James        |Sales     |3000  |1   |\n|James        |Sales     |3000  |1   |\n|Robert       |Sales     |4100  |3   |\n|Saif         |Sales     |4100  |3   |\n|Michael      |Sales     |4600  |5   |\n+-------------+----------+------+----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+----+\n|employee_name|department|salary|rank|\n+-------------+----------+------+----+\n|Maria        |Finance   |3000  |1   |\n|Scott        |Finance   |3300  |2   |\n|Jen          |Finance   |3900  |3   |\n|Kumar        |Marketing |2000  |1   |\n|Jeff         |Marketing |3000  |2   |\n|James        |Sales     |3000  |1   |\n|James        |Sales     |3000  |1   |\n|Robert       |Sales     |4100  |3   |\n|Saif         |Sales     |4100  |3   |\n|Michael      |Sales     |4600  |5   |\n+-------------+----------+------+----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###This is the same as the RANK function in SQL.\n\n\n***\n---\n\n\n\n##2.3 dense_rank Window Function\n\n\n**dense_rank() window function is used to get the result with rank of rows within a window partition without any gaps. This is similar to rank() function difference being rank function leaves gaps in rank when there are ties.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"93c271a9-cc4d-4017-a1b5-efcd406bbc8b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\"\"\" dens_rank\"\"\"\n\ndf.withColumn(\"dense_rank\", dense_rank().over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68618748-560e-4253-b549-1cb989ed4e5c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+----------+\n|employee_name|department|salary|dense_rank|\n+-------------+----------+------+----------+\n|Maria        |Finance   |3000  |1         |\n|Scott        |Finance   |3300  |2         |\n|Jen          |Finance   |3900  |3         |\n|Kumar        |Marketing |2000  |1         |\n|Jeff         |Marketing |3000  |2         |\n|James        |Sales     |3000  |1         |\n|James        |Sales     |3000  |1         |\n|Robert       |Sales     |4100  |2         |\n|Saif         |Sales     |4100  |2         |\n|Michael      |Sales     |4600  |3         |\n+-------------+----------+------+----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+----------+\n|employee_name|department|salary|dense_rank|\n+-------------+----------+------+----------+\n|Maria        |Finance   |3000  |1         |\n|Scott        |Finance   |3300  |2         |\n|Jen          |Finance   |3900  |3         |\n|Kumar        |Marketing |2000  |1         |\n|Jeff         |Marketing |3000  |2         |\n|James        |Sales     |3000  |1         |\n|James        |Sales     |3000  |1         |\n|Robert       |Sales     |4100  |2         |\n|Saif         |Sales     |4100  |2         |\n|Michael      |Sales     |4600  |3         |\n+-------------+----------+------+----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**This is the same as the DENSE_RANK function in SQL.**\n\n###2.4 percent_rank Window Function"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8b0dedca-40a4-4ef0-9db2-e5d160b1c2f4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.withColumn('percent_rank', percent_rank().over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"99006a77-e89a-4b15-bdc6-9cd18bd920ec","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+------------+\n|employee_name|department|salary|percent_rank|\n+-------------+----------+------+------------+\n|Maria        |Finance   |3000  |0.0         |\n|Scott        |Finance   |3300  |0.5         |\n|Jen          |Finance   |3900  |1.0         |\n|Kumar        |Marketing |2000  |0.0         |\n|Jeff         |Marketing |3000  |1.0         |\n|James        |Sales     |3000  |0.0         |\n|James        |Sales     |3000  |0.0         |\n|Robert       |Sales     |4100  |0.5         |\n|Saif         |Sales     |4100  |0.5         |\n|Michael      |Sales     |4600  |1.0         |\n+-------------+----------+------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+------------+\n|employee_name|department|salary|percent_rank|\n+-------------+----------+------+------------+\n|Maria        |Finance   |3000  |0.0         |\n|Scott        |Finance   |3300  |0.5         |\n|Jen          |Finance   |3900  |1.0         |\n|Kumar        |Marketing |2000  |0.0         |\n|Jeff         |Marketing |3000  |1.0         |\n|James        |Sales     |3000  |0.0         |\n|James        |Sales     |3000  |0.0         |\n|Robert       |Sales     |4100  |0.5         |\n|Saif         |Sales     |4100  |0.5         |\n|Michael      |Sales     |4600  |1.0         |\n+-------------+----------+------+------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###This is the same as the PERCENT_RANK function in SQL.\n\n---\n###2.5 ntile Window Function\n\n\n\n**ntile() window function returns the relative rank of result rows within a window partition. In below example we have used 2 as an argument to ntile hence it returns ranking between 2 values (1 and 2)**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"140c875c-63ed-4fa3-8d1f-4d40d0e6d0cd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\"\"\"ntile\"\"\"\n\ndf.withColumn(\"ntile\", ntile(2).over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5cda73a2-7158-401d-8b5a-be472076ffce","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+-----+\n|employee_name|department|salary|ntile|\n+-------------+----------+------+-----+\n|Maria        |Finance   |3000  |1    |\n|Scott        |Finance   |3300  |1    |\n|Jen          |Finance   |3900  |2    |\n|Kumar        |Marketing |2000  |1    |\n|Jeff         |Marketing |3000  |2    |\n|James        |Sales     |3000  |1    |\n|James        |Sales     |3000  |1    |\n|Robert       |Sales     |4100  |1    |\n|Saif         |Sales     |4100  |2    |\n|Michael      |Sales     |4600  |2    |\n+-------------+----------+------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+-----+\n|employee_name|department|salary|ntile|\n+-------------+----------+------+-----+\n|Maria        |Finance   |3000  |1    |\n|Scott        |Finance   |3300  |1    |\n|Jen          |Finance   |3900  |2    |\n|Kumar        |Marketing |2000  |1    |\n|Jeff         |Marketing |3000  |2    |\n|James        |Sales     |3000  |1    |\n|James        |Sales     |3000  |1    |\n|Robert       |Sales     |4100  |1    |\n|Saif         |Sales     |4100  |2    |\n|Michael      |Sales     |4600  |2    |\n+-------------+----------+------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**This is the same as the NTILE function in SQL.**\n\n---\n\n\n##3. PySpark Window Analytic functions\n\n\n###3.1 cume_dist Window Function\n\n\n**cume_dist() window function is used to get the cumulative distribution of values within a window partition.**\n\n**This is the same as the DENSE_RANK function in SQL.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79f0c2f1-3672-4667-bcea-4a4078e2ef1f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\"\"\"cume_dist\"\"\"\n\ndf.withColumn(\"cume_dist\", cume_dist().over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"72087cde-8b06-4ffa-987d-7d09c96306ef","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+------------------+\n|employee_name|department|salary|cume_dist         |\n+-------------+----------+------+------------------+\n|Maria        |Finance   |3000  |0.3333333333333333|\n|Scott        |Finance   |3300  |0.6666666666666666|\n|Jen          |Finance   |3900  |1.0               |\n|Kumar        |Marketing |2000  |0.5               |\n|Jeff         |Marketing |3000  |1.0               |\n|James        |Sales     |3000  |0.4               |\n|James        |Sales     |3000  |0.4               |\n|Robert       |Sales     |4100  |0.8               |\n|Saif         |Sales     |4100  |0.8               |\n|Michael      |Sales     |4600  |1.0               |\n+-------------+----------+------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+------------------+\n|employee_name|department|salary|cume_dist         |\n+-------------+----------+------+------------------+\n|Maria        |Finance   |3000  |0.3333333333333333|\n|Scott        |Finance   |3300  |0.6666666666666666|\n|Jen          |Finance   |3900  |1.0               |\n|Kumar        |Marketing |2000  |0.5               |\n|Jeff         |Marketing |3000  |1.0               |\n|James        |Sales     |3000  |0.4               |\n|James        |Sales     |3000  |0.4               |\n|Robert       |Sales     |4100  |0.8               |\n|Saif         |Sales     |4100  |0.8               |\n|Michael      |Sales     |4600  |1.0               |\n+-------------+----------+------+------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###3.2 lag Window Function\n\n\n**This is the same as the LAG function in SQL.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8a627c6f-564a-45fa-b3a8-469ae4497b81","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\"\"\"lag\"\"\"\n\ndf.withColumn(\"lag\", lag(\"salary\", 2).over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"db0ff8f2-d009-4945-aaa5-816c16c40ecf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+----+\n|employee_name|department|salary|lag |\n+-------------+----------+------+----+\n|Maria        |Finance   |3000  |null|\n|Scott        |Finance   |3300  |null|\n|Jen          |Finance   |3900  |3000|\n|Kumar        |Marketing |2000  |null|\n|Jeff         |Marketing |3000  |null|\n|James        |Sales     |3000  |null|\n|James        |Sales     |3000  |null|\n|Robert       |Sales     |4100  |3000|\n|Saif         |Sales     |4100  |3000|\n|Michael      |Sales     |4600  |4100|\n+-------------+----------+------+----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+----+\n|employee_name|department|salary|lag |\n+-------------+----------+------+----+\n|Maria        |Finance   |3000  |null|\n|Scott        |Finance   |3300  |null|\n|Jen          |Finance   |3900  |3000|\n|Kumar        |Marketing |2000  |null|\n|Jeff         |Marketing |3000  |null|\n|James        |Sales     |3000  |null|\n|James        |Sales     |3000  |null|\n|Robert       |Sales     |4100  |3000|\n|Saif         |Sales     |4100  |3000|\n|Michael      |Sales     |4600  |4100|\n+-------------+----------+------+----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##3.3 lead Window Function\n\n\n**This is the same as the LEAD function in SQL.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9432e095-31ff-4964-bb7c-759bfb50e7ef","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\"\"\"lead\"\"\"\n\ndf.withColumn(\"lead\", lead(\"salary\", 2).over(windowSpec)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"abaf1048-77e5-46be-91b3-4beb3c6f4a2e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+----+\n|employee_name|department|salary|lead|\n+-------------+----------+------+----+\n|Maria        |Finance   |3000  |3900|\n|Scott        |Finance   |3300  |null|\n|Jen          |Finance   |3900  |null|\n|Kumar        |Marketing |2000  |null|\n|Jeff         |Marketing |3000  |null|\n|James        |Sales     |3000  |4100|\n|James        |Sales     |3000  |4100|\n|Robert       |Sales     |4100  |4600|\n|Saif         |Sales     |4100  |null|\n|Michael      |Sales     |4600  |null|\n+-------------+----------+------+----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+----+\n|employee_name|department|salary|lead|\n+-------------+----------+------+----+\n|Maria        |Finance   |3000  |3900|\n|Scott        |Finance   |3300  |null|\n|Jen          |Finance   |3900  |null|\n|Kumar        |Marketing |2000  |null|\n|Jeff         |Marketing |3000  |null|\n|James        |Sales     |3000  |4100|\n|James        |Sales     |3000  |4100|\n|Robert       |Sales     |4100  |4600|\n|Saif         |Sales     |4100  |null|\n|Michael      |Sales     |4600  |null|\n+-------------+----------+------+----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##4. PySpark Window Aggregate Functions\n\n\n**In this section, I will explain how to calculate sum, min, max for each department using PySpark SQL Aggregate window functions and WindowSpec. When working with Aggregate functions, we don’t need to use order by clause.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9aedf34c-720d-43d8-86d1-e0090b98ac7f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["windowSpecAgg = Window.partitionBy(\"department\")\ndf.withColumn(\"row\", row_number().over(windowSpec))\\\n.withColumn(\"avg\", avg(\"salary\").over(windowSpecAgg))\\\n.withColumn(\"sum\", sum(\"salary\").over(windowSpecAgg))\\\n.withColumn(\"min\", min(\"salary\").over(windowSpecAgg))\\\n.withColumn(\"max\", max(\"salary\").over(windowSpecAgg))\\\n.where(col(\"row\")==1).select(\"department\", \"avg\", \"sum\", \"min\", \"max\")\\\n.show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0eda0536-cd77-4eb6-b6b4-9c1dbb61631f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+------+-----+----+----+\n|department|avg   |sum  |min |max |\n+----------+------+-----+----+----+\n|Finance   |3400.0|10200|3000|3900|\n|Marketing |2500.0|5000 |2000|3000|\n|Sales     |3760.0|18800|3000|4600|\n+----------+------+-----+----+----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+------+-----+----+----+\n|department|avg   |sum  |min |max |\n+----------+------+-----+----+----+\n|Finance   |3400.0|10200|3000|3900|\n|Marketing |2500.0|5000 |2000|3000|\n|Sales     |3760.0|18800|3000|4600|\n+----------+------+-----+----+----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df.withColumn(\"row\", row_number().over(windowSpec))\\\n.withColumn(\"avg\", avg(\"salary\").over(windowSpecAgg))\\\n.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"221f6da7-e7e1-4bd8-a79c-d53c897fa1d6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------+----------+------+---+------+\n|employee_name|department|salary|row|   avg|\n+-------------+----------+------+---+------+\n|        Maria|   Finance|  3000|  1|3400.0|\n|        Scott|   Finance|  3300|  2|3400.0|\n|          Jen|   Finance|  3900|  3|3400.0|\n|        Kumar| Marketing|  2000|  1|2500.0|\n|         Jeff| Marketing|  3000|  2|2500.0|\n|        James|     Sales|  3000|  1|3760.0|\n|        James|     Sales|  3000|  2|3760.0|\n|       Robert|     Sales|  4100|  3|3760.0|\n|         Saif|     Sales|  4100|  4|3760.0|\n|      Michael|     Sales|  4600|  5|3760.0|\n+-------------+----------+------+---+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------+----------+------+---+------+\n|employee_name|department|salary|row|   avg|\n+-------------+----------+------+---+------+\n|        Maria|   Finance|  3000|  1|3400.0|\n|        Scott|   Finance|  3300|  2|3400.0|\n|          Jen|   Finance|  3900|  3|3400.0|\n|        Kumar| Marketing|  2000|  1|2500.0|\n|         Jeff| Marketing|  3000|  2|2500.0|\n|        James|     Sales|  3000|  1|3760.0|\n|        James|     Sales|  3000|  2|3760.0|\n|       Robert|     Sales|  4100|  3|3760.0|\n|         Saif|     Sales|  4100|  4|3760.0|\n|      Michael|     Sales|  4600|  5|3760.0|\n+-------------+----------+------+---+------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark Window Functions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4059022665744807}},"nbformat":4,"nbformat_minor":0}
