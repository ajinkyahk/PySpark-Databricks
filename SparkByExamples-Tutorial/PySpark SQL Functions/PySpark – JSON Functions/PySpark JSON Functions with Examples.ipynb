{"cells":[{"cell_type":"markdown","source":["#PySpark JSON Functions with Examples\n\n---\n\n\n**PySpark JSON functions are used to query or extract the elements from JSON string of DataFrame column by path, convert it to struct, mapt type e.t.c, In this article, I will explain the most used JSON SQL functions with Python examples.**\n\n\n---\n\n##1. PySpark JSON Functions\n\n- from_json() – Converts JSON string into Struct type or Map type.\n\n- to_json() – Converts MapType or Struct type to JSON string.\n\n- json_tuple() – Extract the Data from JSON and create them as a new columns.\n\n- get_json_object() – Extracts JSON element from a JSON string based on json path specified.\n\n- schema_of_json() – Create schema string from JSON string\n\n\n---\n\n\n###1.1. Create DataFrame with Column contains JSON String\n\n\n**In order to explain these JSON functions first, let’s create DataFrame with a column contains JSON string.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9126b7de-59d3-45e9-94ea-aecbfc447bba","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["\njsonString = \"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"\ndf = spark.createDataFrame(data=[(1, jsonString)],schema=[\"id\", \"value\"])\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5999fbbf-c180-4d14-9486-62bdd5854776","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+--------------------------------------------------------------------------+\n|id |value                                                                     |\n+---+--------------------------------------------------------------------------+\n|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n+---+--------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+--------------------------------------------------------------------------+\n|id |value                                                                     |\n+---+--------------------------------------------------------------------------+\n|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n+---+--------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##2. PySpark JSON Functions Examples\n\n\n###2.1. from_json()\n\n\n**PySpark from_json() function is used to convert JSON string into Struct type or Map type. The below example converts JSON string to Map key-value pair. I will leave it to you to convert to struct type. Refer, Convert JSON string to Struct type column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7f07ed9e-6eab-43cd-b7cc-b024c3e10e6a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import from_json\nfrom pyspark.sql.types import StringType, MapType, StructType, StructField"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0abb9e1a-73f7-4ee4-b5b0-8ce7367015a8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df2 = df.withColumn(\"value\", from_json(df.value, MapType(StringType(), StringType())))\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4396a6d4-1f9c-4faf-9288-b07126f8e916","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- id: long (nullable = true)\n |-- value: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+---+---------------------------------------------------------------------------+\n|id |value                                                                      |\n+---+---------------------------------------------------------------------------+\n|1  |{Zipcode -> 704, ZipCodeType -> STANDARD, City -> PARC PARQUE, State -> PR}|\n+---+---------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- id: long (nullable = true)\n |-- value: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+---+---------------------------------------------------------------------------+\n|id |value                                                                      |\n+---+---------------------------------------------------------------------------+\n|1  |{Zipcode -> 704, ZipCodeType -> STANDARD, City -> PARC PARQUE, State -> PR}|\n+---+---------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["df3 = df2.rdd.map(lambda x: (x.id, x.value['Zipcode'], x.value['City'], x.value['State']))\\\n.toDF(['id', 'zipcode', 'city', 'state'])\ndf3.printSchema()\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0bd4e12b-319a-481b-9c19-92e6f2ecdb91","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- id: long (nullable = true)\n |-- zipcode: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n\n+---+-------+-----------+-----+\n|id |zipcode|city       |state|\n+---+-------+-----------+-----+\n|1  |704    |PARC PARQUE|PR   |\n+---+-------+-----------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- id: long (nullable = true)\n |-- zipcode: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n\n+---+-------+-----------+-----+\n|id |zipcode|city       |state|\n+---+-------+-----------+-----+\n|1  |704    |PARC PARQUE|PR   |\n+---+-------+-----------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b534fad-e4f9-475a-9ed4-7d709385c639","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["schema = StructType([\n    StructField(\"Zipcode\", StringType(), True),\n    StructField(\"ZipcodeType\", StringType(), True),\n    StructField(\"City\", StringType(), True),\n    StructField(\"State\", StringType(), True)\n])\n\ndf4  = df.withColumn(\"Value\", from_json(col(\"value\"), schema))\ndf4.printSchema()\ndf4.show(truncate=False)\n\n#convert to multiple columns\ndf5 = df4.select(\"id\", \"value.*\")\ndf5.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5b9d6ae3-7b18-42f3-a713-29f47e564e6a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- id: long (nullable = true)\n |-- Value: struct (nullable = true)\n |    |-- Zipcode: string (nullable = true)\n |    |-- ZipcodeType: string (nullable = true)\n |    |-- City: string (nullable = true)\n |    |-- State: string (nullable = true)\n\n+---+----------------------------+\n|id |Value                       |\n+---+----------------------------+\n|1  |{704, null, PARC PARQUE, PR}|\n+---+----------------------------+\n\n+---+-------+-----------+-----------+-----+\n|id |Zipcode|ZipcodeType|City       |State|\n+---+-------+-----------+-----------+-----+\n|1  |704    |null       |PARC PARQUE|PR   |\n+---+-------+-----------+-----------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- id: long (nullable = true)\n |-- Value: struct (nullable = true)\n |    |-- Zipcode: string (nullable = true)\n |    |-- ZipcodeType: string (nullable = true)\n |    |-- City: string (nullable = true)\n |    |-- State: string (nullable = true)\n\n+---+----------------------------+\n|id |Value                       |\n+---+----------------------------+\n|1  |{704, null, PARC PARQUE, PR}|\n+---+----------------------------+\n\n+---+-------+-----------+-----------+-----+\n|id |Zipcode|ZipcodeType|City       |State|\n+---+-------+-----------+-----------+-----+\n|1  |704    |null       |PARC PARQUE|PR   |\n+---+-------+-----------+-----------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.2. to_json()\n\n\n**to_json() function is used to convert DataFrame columns MapType or Struct type to JSON string. Here, I am using df2 that created from above from_json() example.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa0dff0e-8d9f-4a7b-8b2d-c1a2449f1d05","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#MapType\ndf2.withColumn(\"Value\", to_json(col(\"value\")))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"38ec4678-e113-4646-b4cd-0560f2e84073","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+----------------------------------------------------------------------------+\n|id |Value                                                                       |\n+---+----------------------------------------------------------------------------+\n|1  |{\"Zipcode\":\"704\",\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n+---+----------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+----------------------------------------------------------------------------+\n|id |Value                                                                       |\n+---+----------------------------------------------------------------------------+\n|1  |{\"Zipcode\":\"704\",\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n+---+----------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#StuctType\ndf4.withColumn(\"value\", to_json(col(\"value\")))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f64b905a-3b67-433d-8d96-70f78e73f7b2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+---------------------------------------------------+\n|id |value                                              |\n+---+---------------------------------------------------+\n|1  |{\"Zipcode\":\"704\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n+---+---------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+---------------------------------------------------+\n|id |value                                              |\n+---+---------------------------------------------------+\n|1  |{\"Zipcode\":\"704\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n+---+---------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.3. json_tuple()\n\n\n**Function json_tuple() is used the query or extract the elements from JSON column and create the result as a new columns.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4832d5dc-06e0-4305-aef5-a917a5167a97","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.select(col(\"id\"), json_tuple(col(\"value\"), \"Zipcode\", \"ZipCodeType\", \"City\", \"State\"))\\\n.toDF(\"id\", \"Zipcode\", \"ZipCodeType\", \"City\", \"State\")\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5bab61b-5daa-4f1c-a4a7-8a3b26f14228","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-------+-----------+-----------+-----+\n|id |Zipcode|ZipCodeType|City       |State|\n+---+-------+-----------+-----------+-----+\n|1  |704    |STANDARD   |PARC PARQUE|PR   |\n+---+-------+-----------+-----------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-------+-----------+-----------+-----+\n|id |Zipcode|ZipCodeType|City       |State|\n+---+-------+-----------+-----------+-----+\n|1  |704    |STANDARD   |PARC PARQUE|PR   |\n+---+-------+-----------+-----------+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.4. get_json_object()\n\n**get_json_object() is used to extract the JSON string based on path from the JSON column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c8b0318-f1d6-47c9-ae4b-4857782da65a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.select(col(\"id\"), get_json_object(col(\"value\"), \"$.ZipCodeType\").alias(\"ZipCodeType\"))\\\n.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7b436671-85f3-400e-a0b7-94a766a9487e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+-----------+\n|id |ZipCodeType|\n+---+-----------+\n|1  |STANDARD   |\n+---+-----------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+-----------+\n|id |ZipCodeType|\n+---+-----------+\n|1  |STANDARD   |\n+---+-----------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["###2.5. schema_of_json()\n\n**Use schema_of_json() to create schema string from JSON string column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5e3887b8-fc0f-4667-9385-8f02e2ea8c7c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["schemaStr = spark.range(1)\\\n.select(schema_of_json(lit(\"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\")))\\\n.collect()[0][0]\nprint(schemaStr)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"424a37a1-d933-48aa-ba19-efd7e4a86907","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"STRUCT<City: STRING, State: STRING, ZipCodeType: STRING, Zipcode: BIGINT>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["STRUCT<City: STRING, State: STRING, ZipCodeType: STRING, Zipcode: BIGINT>\n"]}}],"execution_count":0},{"cell_type":"code","source":["schemaStr = spark.range(1)\nschemaStr.printSchema()\nschemaStr.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"093d0713-d07c-4eee-9659-82537be947ca","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- id: long (nullable = false)\n\n+---+\n| id|\n+---+\n|  0|\n+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- id: long (nullable = false)\n\n+---+\n| id|\n+---+\n|  0|\n+---+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["schemaStr = spark.range(1)\\\n.select(schema_of_json(lit(\"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"))).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e2b2843-0499-4a39-8dfc-13c79e589765","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------------------------------------------------------------------------------------------+\n|schema_of_json({\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"})|\n+------------------------------------------------------------------------------------------+\n|STRUCT<City: STRING, State: STRING, ZipCodeType: STRING, Zipcode: BIGINT>                 |\n+------------------------------------------------------------------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------------------------------------------------------------------------------------------+\n|schema_of_json({\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"})|\n+------------------------------------------------------------------------------------------+\n|STRUCT<City: STRING, State: STRING, ZipCodeType: STRING, Zipcode: BIGINT>                 |\n+------------------------------------------------------------------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["help(schema_of_json)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"872c1760-5eef-4fa4-b34b-c161cee301fd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Help on function schema_of_json in module pyspark.sql.functions:\n\nschema_of_json(json: 'ColumnOrName', options: Optional[Dict[str, str]] = None) -> pyspark.sql.column.Column\n    Parses a JSON string and infers its schema in DDL format.\n    \n    .. versionadded:: 2.4.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    json : :class:`~pyspark.sql.Column` or str\n        a JSON string or a foldable string column containing a JSON string.\n    options : dict, optional\n        options to control parsing. accepts the same options as the JSON datasource.\n        See `Data Source Option <https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option>`_\n        in the version you use.\n    \n        .. # noqa\n    \n        .. versionchanged:: 3.0.0\n           It accepts `options` parameter to control schema inferring.\n    \n    Examples\n    --------\n    >>> df = spark.range(1)\n    >>> df.select(schema_of_json(lit('{\"a\": 0}')).alias(\"json\")).collect()\n    [Row(json='STRUCT<a: BIGINT>')]\n    >>> schema = schema_of_json('{a: 1}', {'allowUnquotedFieldNames':'true'})\n    >>> df.select(schema.alias(\"json\")).collect()\n    [Row(json='STRUCT<a: BIGINT>')]\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Help on function schema_of_json in module pyspark.sql.functions:\n\nschema_of_json(json: 'ColumnOrName', options: Optional[Dict[str, str]] = None) -> pyspark.sql.column.Column\n    Parses a JSON string and infers its schema in DDL format.\n    \n    .. versionadded:: 2.4.0\n    \n    .. versionchanged:: 3.4.0\n        Support Spark Connect.\n    \n    Parameters\n    ----------\n    json : :class:`~pyspark.sql.Column` or str\n        a JSON string or a foldable string column containing a JSON string.\n    options : dict, optional\n        options to control parsing. accepts the same options as the JSON datasource.\n        See `Data Source Option <https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option>`_\n        in the version you use.\n    \n        .. # noqa\n    \n        .. versionchanged:: 3.0.0\n           It accepts `options` parameter to control schema inferring.\n    \n    Examples\n    --------\n    >>> df = spark.range(1)\n    >>> df.select(schema_of_json(lit('{\"a\": 0}')).alias(\"json\")).collect()\n    [Row(json='STRUCT<a: BIGINT>')]\n    >>> schema = schema_of_json('{a: 1}', {'allowUnquotedFieldNames':'true'})\n    >>> df.select(schema.alias(\"json\")).collect()\n    [Row(json='STRUCT<a: BIGINT>')]\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark JSON Functions with Examples","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3436139559221558}},"nbformat":4,"nbformat_minor":0}
