{"cells":[{"cell_type":"markdown","source":["#PySpark flatMap() Transformation\n\n\n---\n\n**PySpark flatMap() is a transformation operation that flattens the RDD/DataFrame (array/map DataFrame columns) after applying the function on every element and returns a new PySpark RDD/DataFrame. In this article, you will learn the syntax and usage of the PySpark flatMap() with an example.**\n\n\n---\n\n\n**First, let’s create an RDD from the list.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de323769-d9de-4cda-b40e-7d8565de3d72","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = [\n    \"Project Gutenberg’s\",\n    \"Alice’s Adventures in Wonderland\",\n    \"Project Gutenberg’s\",\n    \"Adventures in Wonderland\",\n    \"Project Gutenberg’s\"\n]\n\nrdd = sc.parallelize(data)\n\nfor element in rdd.collect():\n    print(element)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c53f1f9c-a747-4840-8b12-1867f85e31ff","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Project Gutenberg’s\nAlice’s Adventures in Wonderland\nProject Gutenberg’s\nAdventures in Wonderland\nProject Gutenberg’s\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Project Gutenberg’s\nAlice’s Adventures in Wonderland\nProject Gutenberg’s\nAdventures in Wonderland\nProject Gutenberg’s\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##flatMap() Syntax\n\n\n---\n####flatMap(f, preservesPartitioning=False)\n---\n\n\n\n\n---\n\n\n##flatMap() Example\n\n\n\n**Now, let’s see with an example of how to apply a flatMap() transformation on RDD. In the below example, first, it splits each record by space in an RDD and finally flattens it. Resulting RDD consists of a single word on each record.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"123c0ea1-3f68-4507-8ed0-ad83387fb705","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["rdd2 = rdd.flatMap(lambda x: x.split(\" \"))\n\nfor element in rdd2.collect():\n    print(element)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4242762-25b6-4c30-a19b-34afcca2b0a0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Project\nGutenberg’s\nAlice’s\nAdventures\nin\nWonderland\nProject\nGutenberg’s\nAdventures\nin\nWonderland\nProject\nGutenberg’s\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Project\nGutenberg’s\nAlice’s\nAdventures\nin\nWonderland\nProject\nGutenberg’s\nAdventures\nin\nWonderland\nProject\nGutenberg’s\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##Using flatMap() transformation on DataFrame\n\n---\n\n\n**Unfortunately, PySpark DataFame doesn’t have flatMap() transformation however, DataFrame has explode() SQL function that is used to flatten the column. Below is a complete example.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"20da6b90-4741-4f5a-a497-dd736a868fc5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import explode\n\n\narrayData = [\n    ('James',['Java','Scala'],{'hair':'black','eye':'brown'}),\n    ('Michael',['Spark','Java',None],{'hair':'brown','eye':None}),\n    ('Robert',['CSharp',''],{'hair':'red','eye':''}),\n    ('Washington',None,None),\n    ('Jefferson',['1','2'],{})\n]\n\ndf = spark.createDataFrame(data=arrayData, schema= ['name', 'knownlanguages', 'properties'])\ndf2 = df.select(df.name, explode(df.knownlanguages))\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ddc154a1-3e68-4663-8e88-7c7eacadc0b5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- col: string (nullable = true)\n\n+---------+------+\n|name     |col   |\n+---------+------+\n|James    |Java  |\n|James    |Scala |\n|Michael  |Spark |\n|Michael  |Java  |\n|Michael  |null  |\n|Robert   |CSharp|\n|Robert   |      |\n|Jefferson|1     |\n|Jefferson|2     |\n+---------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- col: string (nullable = true)\n\n+---------+------+\n|name     |col   |\n+---------+------+\n|James    |Java  |\n|James    |Scala |\n|Michael  |Spark |\n|Michael  |Java  |\n|Michael  |null  |\n|Robert   |CSharp|\n|Robert   |      |\n|Jefferson|1     |\n|Jefferson|2     |\n+---------+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**This example flattens the array column “knownLanguages” and yields below output**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f5798fc-36a1-4b51-aa82-9e911520a8c9","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##Conclusion\n\n**In conclusion, you have learned how to apply a PySpark flatMap() transformation to flattens the array or map columns and also learned how to use alternatives for DataFrame.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1516324a-3453-4609-b6f5-2d17fece854d","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark flatMap() Transformation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4425648766185676}},"nbformat":4,"nbformat_minor":0}
