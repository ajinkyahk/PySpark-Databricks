{"cells":[{"cell_type":"markdown","source":["#PySpark StructType & StructField\n\n---\n\n\n**PySpark StructType & StructField classes are used to programmatically specify the schema to the DataFrame and create complex columns like nested struct, array, and map columns. StructType is a collection of StructField’s that defines column name, column data type, boolean to specify if the field can be nullable or not and metadata.**\n\n\n---\n\n**Though PySpark infers a schema from data, sometimes we may need to define our own column names and data types and this article explains how to define simple, nested, and complex schemas.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"462f478b-57b9-4ce7-be90-28407dfd2b88","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##1. StructType – Defines the structure of the Dataframe\n\n---\n\n\n**PySpark provides from pyspark.sql.types import StructType class to define the structure of the DataFrame.**\n\n***StructType is a collection or list of StructField objects.***\n\n---\n\n**PySpark printSchema() method on the DataFrame shows StructType columns as struct.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1b5a6ee5-d138-43bb-bffc-d83a736a5bf4","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##2. StructField – Defines the metadata of the DataFrame column\n\n\n---\n\n\n**PySpark provides pyspark.sql.types import StructField class to define the columns which include column name(String), column type (DataType), nullable column (Boolean) and metadata (MetaData)**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2a0e5177-6266-4b1b-a078-7244e5cba371","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##3. Using PySpark StructType & StructField with DataFrame\n\n\n---\n\n**While creating a PySpark DataFrame we can specify the structure using StructType and StructField classes. As specified in the introduction, StructType is a collection of StructField’s which is used to define the column name, data type, and a flag for nullable or not. Using StructField we can also add nested struct schema, ArrayType for arrays, and MapType for key-value pairs.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29f2fd2a-6431-4018-9142-d2d0665e5d9d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType\n\n\ndata = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n        (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n       ]\n\nschema = StructType([\n    StructField('firstname', StringType(), True),\n    StructField('middlename', StringType(), True),\n    StructField('lastname', StringType(), True),\n    StructField('id', StringType(), True),\n    StructField('gender', StringType(), True),\n    StructField('salary', IntegerType(), True),\n])\n\n\ndf = spark.createDataFrame(data=data, schema=schema)\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"14b26d3f-fa7c-4086-8a19-ee84b7954368","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|id   |gender|salary|\n+---------+----------+--------+-----+------+------+\n|James    |          |Smith   |36636|M     |3000  |\n|Michael  |Rose      |        |40288|M     |4000  |\n|Robert   |          |Williams|42114|M     |4000  |\n|Maria    |Anne      |Jones   |39192|F     |4000  |\n|Jen      |Mary      |Brown   |     |F     |-1    |\n+---------+----------+--------+-----+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##4. Defining Nested StructType object struct\n\n---\n\n**While working on DataFrame we often need to work with the nested struct column and this can be defined using StructType.**\n\n\n---\n\n***In the below example column “name” data type is StructType which is nested.***"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d83c58a8-e5ce-4a93-bee3-1c050be407ed","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["structureData = [\n    (('James','','Smith'),'36636','M',3100),\n    (('Michael', 'Rose', ''), '40288', 'M',4300),\n    (('Robert','','Williams'),'42114','M',1400),\n    (('Maria','Anne','Jones'),'39192','F',5500),\n    (('Jen','Mary','Brown'),'','F',-1)\n]\n\nstructureSchema = StructType([\n    StructField('name', StructType([\n        StructField('firstname', StringType(), True),\n        StructField('middlename', StringType(), True),\n        StructField('lastname', StringType(), True),\n    ])),\n    StructField('id', StringType(), True),\n    StructField('gender', StringType(), True),\n    StructField('salary', IntegerType(), True)\n])\n\ndf2 = spark.createDataFrame(data=structureData, schema=structureSchema)\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68f15085-07d6-4dba-b8df-c9b367686420","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+--------------------+-----+------+------+\n|name                |id   |gender|salary|\n+--------------------+-----+------+------+\n|{James, , Smith}    |36636|M     |3100  |\n|{Michael, Rose, }   |40288|M     |4300  |\n|{Robert, , Williams}|42114|M     |1400  |\n|{Maria, Anne, Jones}|39192|F     |5500  |\n|{Jen, Mary, Brown}  |     |F     |-1    |\n+--------------------+-----+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+--------------------+-----+------+------+\n|name                |id   |gender|salary|\n+--------------------+-----+------+------+\n|{James, , Smith}    |36636|M     |3100  |\n|{Michael, Rose, }   |40288|M     |4300  |\n|{Robert, , Williams}|42114|M     |1400  |\n|{Maria, Anne, Jones}|39192|F     |5500  |\n|{Jen, Mary, Brown}  |     |F     |-1    |\n+--------------------+-----+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##5. Adding & Changing struct of the DataFrame\n\n\n---\n\n**Using PySpark SQL function struct(), we can change the struct of the existing DataFrame and add a new StructType to it. The below example demonstrates how to copy the columns from one structure to another and adding a new column. PySpark Column Class also provides some functions to work with the StructType column.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f15cc04-87eb-46ff-b70f-be53cc0f47f1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import col,struct,when\n\nupdateDF = df2.withColumn('OtherInfo',\n            struct(col('id').alias('identifier'),\n                   col('gender').alias('gender'),\n                   col('salary').alias('salary'),\n                   when(col('salary').cast(IntegerType()) < 2000, \"Low\")\n                   .when(col('salary').cast(IntegerType())<4000, \"Medium\")\n                   .otherwise('High').alias('Salary_Grade')                 \n                )).drop('id', 'gender', 'salary')\n\n\nupdateDF.printSchema()\nupdateDF.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fb7ad5d2-0a9f-4e50-a7bd-0f9d50c53d27","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- OtherInfo: struct (nullable = false)\n |    |-- identifier: string (nullable = true)\n |    |-- gender: string (nullable = true)\n |    |-- salary: integer (nullable = true)\n |    |-- Salary_Grade: string (nullable = false)\n\n+--------------------+------------------------+\n|name                |OtherInfo               |\n+--------------------+------------------------+\n|{James, , Smith}    |{36636, M, 3100, Medium}|\n|{Michael, Rose, }   |{40288, M, 4300, High}  |\n|{Robert, , Williams}|{42114, M, 1400, Low}   |\n|{Maria, Anne, Jones}|{39192, F, 5500, High}  |\n|{Jen, Mary, Brown}  |{, F, -1, Low}          |\n+--------------------+------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- OtherInfo: struct (nullable = false)\n |    |-- identifier: string (nullable = true)\n |    |-- gender: string (nullable = true)\n |    |-- salary: integer (nullable = true)\n |    |-- Salary_Grade: string (nullable = false)\n\n+--------------------+------------------------+\n|name                |OtherInfo               |\n+--------------------+------------------------+\n|{James, , Smith}    |{36636, M, 3100, Medium}|\n|{Michael, Rose, }   |{40288, M, 4300, High}  |\n|{Robert, , Williams}|{42114, M, 1400, Low}   |\n|{Maria, Anne, Jones}|{39192, F, 5500, High}  |\n|{Jen, Mary, Brown}  |{, F, -1, Low}          |\n+--------------------+------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##6. Using SQL ArrayType and MapType\n\n\n---\n\n\n**SQL StructType also supports ArrayType and MapType to define the DataFrame columns for array and map collections respectively. On the below example, column hobbies defined as ArrayType(StringType) and properties defined as MapType(StringType,StringType) meaning both key and value as String.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"37dd1366-ba9e-471c-9ccd-48d40e6b446f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.types import ArrayType, MapType\n\narrayStructureSchema = StructType([\n    StructField('name', StructType([\n        StructField('firstname', StringType(), True),\n        StructField('middlename', StringType(), True),\n        StructField('lastname', StringType(), True)\n])),\n    StructField('hobbies', ArrayType(StringType()), True),\n    StructField('properties', MapType(StringType(), StringType()), True)\n])\n\narrayStructureDF = spark.createDataFrame(data=[], schema=arrayStructureSchema)\narrayStructureDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b738fd3-8684-48d8-9c89-c862faf08e27","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- hobbies: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- hobbies: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##7. Creating StructType object struct from JSON file\n\n---\n\n**If you have too many columns and the structure of the DataFrame changes now and then, it’s a good practice to load the SQL StructType schema from JSON file. You can get the schema by using df2.schema.json() , store this in a file and will use it to create a the schema from this file.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4e75071e-6a30-4219-8d4c-11e2a92ff979","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(df2.schema.json())\n\njson_data = df2.schema.json()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1a3d6046-a6cd-42a1-93ee-044a7e72013c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"{\"fields\":[{\"metadata\":{},\"name\":\"name\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"firstname\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"middlename\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"lastname\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"gender\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"salary\",\"nullable\":true,\"type\":\"integer\"}],\"type\":\"struct\"}\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["{\"fields\":[{\"metadata\":{},\"name\":\"name\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"firstname\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"middlename\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"lastname\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"gender\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"salary\",\"nullable\":true,\"type\":\"integer\"}],\"type\":\"struct\"}\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Alternatively, you could also use df.schema.simpleString(), this will return an relatively simpler schema format.**\n\n***Now let’s load the json file and use it to create a DataFrame.***"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d38fd047-7e77-4c34-ac52-2921a8ca6892","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import json\nschemaFromJson = StructType.fromJson(json.loads(json_data))\n\ndf3 = spark.createDataFrame(sc.parallelize(structureData), schemaFromJson)\ndf3.printSchema()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"934a5738-0e0e-48e1-bac6-0fc0d6016841","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##8. Creating StructType object struct from DDL String\n\n---\n\n\n**Like loading structure from JSON string, we can also create it from DLL ( by using T._parse_datatype_string(ddl_schema_string).**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8627ab5c-182e-41e9-8696-f439c8640682","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.types as T\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b8ae0dac-8630-445f-b3fe-b403b7c759d2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ddlSchemaStr = \"`fullName` STRUCT<`first`: STRING, `last`: STRING,\\\n `middle`: STRING>,`age` INT,`gender` STRING\"\n\nddl_schema = T._parse_datatype_string(ddlSchemaStr)\nddl_schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"edeb633b-4664-4d56-9392-78b590976b03","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[275]: StructType([StructField('fullName', StructType([StructField('first', StringType(), True), StructField('last', StringType(), True), StructField('middle', StringType(), True)]), True), StructField('age', IntegerType(), True), StructField('gender', StringType(), True)])","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[275]: StructType([StructField('fullName', StructType([StructField('first', StringType(), True), StructField('last', StringType(), True), StructField('middle', StringType(), True)]), True), StructField('age', IntegerType(), True), StructField('gender', StringType(), True)])"]}}],"execution_count":0},{"cell_type":"markdown","source":["##9. Checking if a Column Exists in a DataFrame\n\n---\n\n**If you want to perform some checks on metadata of the DataFrame, for example, if a column or field exists in a DataFrame or data type of column; we can easily do this using several functions on SQL StructType and StructField.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"83d76dc0-baa8-4494-bdbf-df00d6057bf4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(df.schema.fieldNames().__contains__(\"firstname\"))\nprint(df.schema.fields.__contains__(StructField(\"firstname\",StringType(),True)))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b7f5905-4e8c-4294-a434-cf0faf8bb483","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"True\nTrue\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["True\nTrue\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark StructType & StructField","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":-1,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":386912842559407}},"nbformat":4,"nbformat_minor":0}
