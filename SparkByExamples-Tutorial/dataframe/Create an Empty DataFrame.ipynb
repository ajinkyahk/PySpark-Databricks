{"cells":[{"cell_type":"markdown","source":["# PySpark – Create an Empty DataFrame & RDD"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c0018e36-5470-411f-9b8d-874fab8c4133","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**While working with files, sometimes we may not receive a file for processing, however, we still need to create a DataFrame manually with the same schema we expect. If we don’t create with the same schema, our operations/transformations (like union’s) on DataFrame fail as we refer to the columns that may not present.**\n\n**To handle situations similar to these, we always need to create a DataFrame with the same schema, which means the same column names and datatypes regardless of the file exists or empty file processing.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e8fd4603-ce94-4d2a-8fa4-2ea54157616c","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## 1. Create Empty RDD in PySpark\n\n---\n\nCreate an empty RDD by using emptyRDD() of SparkContext for example spark.sparkContext.emptyRDD()."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b9335e6e-4266-473a-b892-00fa2a2153b2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# creates empty rdd\n\nemptyRDD = sc.emptyRDD()\nprint(emptyRDD)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"287d8d0e-8fc2-40ac-9d37-8492bf0aac07","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Alternatively you can also get empty RDD by using spark.sparkContext.parallelize([]).**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"81b2057d-c46e-440b-951e-31adeaae69be","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Creates Empty RDD using parallelize\nrdd2 = sc.parallelize([])\nprint(rdd2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e0ca1c0c-b70f-4aff-a591-9c06faa9ad43","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"ParallelCollectionRDD[1] at readRDDFromInputStream at PythonRDD.scala:435\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["ParallelCollectionRDD[1] at readRDDFromInputStream at PythonRDD.scala:435\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 2. Create Empty DataFrame with Schema (StructType)\n\n---\n\n**In order to create an empty PySpark DataFrame manually with schema ( column names & data types) first, Create a schema using StructType and StructField .**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ab2e62b9-0749-43eb-aa29-91a3498b2988","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Create Schema\n\nfrom pyspark.sql.types import StructType, StructField, StringType\n\nschema = StructType([\n        StructField('firstname', StringType(), True),\n        StructField('middlename', StringType(), True),\n        StructField('lastname', StringType(), True)\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"24dddfd2-0dc8-4cb5-bf9b-79394bf9e2d1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**Now use the empty RDD created above and pass it to createDataFrame() of SparkSession along with the schema for column names & data types.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d9bb126-d32e-485a-be5a-124e2a208dd4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Create empty DataFrame from empty RDD\n\ndf = spark.createDataFrame(data=emptyRDD, schema=schema)\ndf.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"897031b5-30f6-408a-98b3-b95f07c11f65","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 3. Convert Empty RDD to DataFrame\n\n---\n\n**You can also create empty DataFrame by converting empty RDD to DataFrame using toDF().**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"257ef396-6400-4445-9186-ef2add119fec","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Convert empty RDD to DataFrame\n\ndf1 = rdd2.toDF(schema=schema)\n\ndf1.printSchema()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"54c984ac-f492-40db-b916-e1925882626e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 4. Create Empty DataFrame with Schema.\n\n---\n\n**here will create it manually with schema and without RDD.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"539b40c4-0879-4a17-bbba-911beb915d8a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Create empty DataFrame directly\n\ndf2 = spark.createDataFrame(data=[], schema=schema)\n\ndf2.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5c6925e3-66fd-4f6e-b3ee-961e557d4b9a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- firstname: string (nullable = true)\n |-- middlename: string (nullable = true)\n |-- lastname: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## 5. Create Empty DataFrame without Schema (no columns)\n\n---\n\n**To create empty DataFrame without schema (no columns) just create a empty schema and use it while creating PySpark DataFrame.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4a5089e-fb05-418f-8884-a070e30b33a9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Create empty DataFrame with no schema (no columns)\n\ndf3 = spark.createDataFrame(data=[], schema=StructType([]))\n\ndf3.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8b41f836-783a-4a04-a12c-eef50deb1b24","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"df07536f-6a6b-4772-afc6-497cfe524321","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Create an Empty DataFrame","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3350744887913014}},"nbformat":4,"nbformat_minor":0}
