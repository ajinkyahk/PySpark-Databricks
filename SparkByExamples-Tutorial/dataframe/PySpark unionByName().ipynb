{"cells":[{"cell_type":"markdown","source":["#PySpark unionByName()\n\n\n---\n\n**The pyspark.sql.DataFrame.unionByName() to merge/union two DataFrames with column names. In PySpark you can easily achieve this using unionByName() transformation, this function also takes param allowMissingColumns with the value True if you have a different number of columns on two DataFrames.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c97eb85c-8954-4de9-b861-13ad63079dea","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##1. Syntax of unionByName()\n\n---\n\nFollowing is the syntax of the unionByName()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4dc1bea2-8417-413c-a06b-956bbaa56978","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["####unionByName() Syntax\n**unionByName(df, allowMissingColumns=True)**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"593ff0c7-4b7e-4d4a-9f16-5858add38025","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##2. Difference between PySpark uionByName() vs union()\n\n\n---\n\n\n\n**The difference between unionByName() function and union() is that this function\nresolves columns by name (not by position). In other words, unionByName() is used to merge two DataFrames by column names instead of by position.**\n\n**unionByName() also provides an argument allowMissingColumns to specify if you have a different column counts. In case you are using an older than Spark 3.1 version, use the below approach to merge DataFrames with different column names.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a613011a-ddd1-4baa-bf56-b306ac8fcd69","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##3. PySpark unionByName() Usage with Examples\n\n\n---\n\n\n**PySpark unionByName() is used to union two DataFrames when you have column names in a different order or even if you have missing columns in any DataFrme, in other words, this function resolves columns by name (not by position).** \n\n---\n\n**First, let’s create DataFrames with the different number of columns.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e46accaf-c752-4c99-ac2b-9fba7326cec4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Create DataFrame df1 with columns name, and id\n\ndata = [\n    (\"James\",34), (\"Michael\",56), \\\n    (\"Robert\",30), (\"Maria\",24)\n]\n\ndf1 = spark.createDataFrame(data = data, schema=[\"name\", \"id\"])\ndf1.printSchema()\ndf1.show(truncate=False)\n\n#Create DataFrame df2 with column name and id\n\ndata2 =  [\n    (34,\"James\"),(45,\"Maria\"), \\\n    (45,\"Jen\"),(34,\"Jeff\")\n]\n\n\ndf2 = spark.createDataFrame(data=data2, schema=[\"id\", \"name\"])\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bf103984-365b-4043-8148-ea4c19b12295","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- id: long (nullable = true)\n\n+-------+---+\n|name   |id |\n+-------+---+\n|James  |34 |\n|Michael|56 |\n|Robert |30 |\n|Maria  |24 |\n+-------+---+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n\n+---+-----+\n|id |name |\n+---+-----+\n|34 |James|\n|45 |Maria|\n|45 |Jen  |\n|34 |Jeff |\n+---+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- id: long (nullable = true)\n\n+-------+---+\n|name   |id |\n+-------+---+\n|James  |34 |\n|Michael|56 |\n|Robert |30 |\n|Maria  |24 |\n+-------+---+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n\n+---+-----+\n|id |name |\n+---+-----+\n|34 |James|\n|45 |Maria|\n|45 |Jen  |\n|34 |Jeff |\n+---+-----+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Now let’s use the PySpark unionByName() to union these two.**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cb87029c-72ed-4490-bc80-407ed42292fa","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#unionByName() example\n\ndf3 = df1.unionByName(df2)\ndf3.printSchema()\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5d7d7f21-22f4-4aa7-a01b-604c2e3e216f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- id: long (nullable = true)\n\n+-------+---+\n|name   |id |\n+-------+---+\n|James  |34 |\n|Michael|56 |\n|Robert |30 |\n|Maria  |24 |\n|James  |34 |\n|Maria  |45 |\n|Jen    |45 |\n|Jeff   |34 |\n+-------+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- id: long (nullable = true)\n\n+-------+---+\n|name   |id |\n+-------+---+\n|James  |34 |\n|Michael|56 |\n|Robert |30 |\n|Maria  |24 |\n|James  |34 |\n|Maria  |45 |\n|Jen    |45 |\n|Jeff   |34 |\n+-------+---+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["##4. Use unionByName() with Different Number of Columns\n\n---\n\n\n**In the above example we have two DataFrames with the same column names but in different order. If you have a different number of columns then use allowMissingColumns=True. When using this, the result of the DataFrmae contains null values for the columns that are missing on the DataFrame.**\n\n\n###Note that param allowMissingColumns is available since Spark 3.1 version."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2c189741-e516-4df1-8b2b-2217cb5d2cf0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#Create DataFrame with different column names\n\ndf1 = spark.createDataFrame([[5,2,6]], [\"col0\", \"col1\", \"col2\"])\ndf1.show(truncate=False)\n\ndf2 = spark.createDataFrame([[6,7,[3,4]]], [\"col1\", \"col2\", \"col3\"])\ndf2.show(truncate=False)\n\n#using allowMissingColumns\ndf3 = df1.unionByName(df2, allowMissingColumns=True)\ndf3.printSchema()\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aac364ea-47c8-4af8-ad95-6ec5492d1d57","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+----+----+\n|col0|col1|col2|\n+----+----+----+\n|5   |2   |6   |\n+----+----+----+\n\n+----+----+------+\n|col1|col2|col3  |\n+----+----+------+\n|6   |7   |[3, 4]|\n+----+----+------+\n\nroot\n |-- col0: long (nullable = true)\n |-- col1: long (nullable = true)\n |-- col2: long (nullable = true)\n |-- col3: array (nullable = true)\n |    |-- element: long (containsNull = true)\n\n+----+----+----+------+\n|col0|col1|col2|col3  |\n+----+----+----+------+\n|5   |2   |6   |null  |\n|null|6   |7   |[3, 4]|\n+----+----+----+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+----+----+\n|col0|col1|col2|\n+----+----+----+\n|5   |2   |6   |\n+----+----+----+\n\n+----+----+------+\n|col1|col2|col3  |\n+----+----+------+\n|6   |7   |[3, 4]|\n+----+----+------+\n\nroot\n |-- col0: long (nullable = true)\n |-- col1: long (nullable = true)\n |-- col2: long (nullable = true)\n |-- col3: array (nullable = true)\n |    |-- element: long (containsNull = true)\n\n+----+----+----+------+\n|col0|col1|col2|col3  |\n+----+----+----+------+\n|5   |2   |6   |null  |\n|null|6   |7   |[3, 4]|\n+----+----+----+------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark unionByName()","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2656410894484123}},"nbformat":4,"nbformat_minor":0}
